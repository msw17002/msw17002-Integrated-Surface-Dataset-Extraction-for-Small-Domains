{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.ncei.noaa.gov/data/global-hourly/access/2019/ [QCLCD]\n",
    "#Times are in UTC\n",
    "#################################################################################################\n",
    "#QUALITY-CHECKS [QC]\n",
    "# 0 = Passed gross limits check\n",
    "# 1 = Passed all quality control checks\n",
    "# 2 = Suspect\n",
    "# 3 = Erroneous\n",
    "# 4 = Passed gross limits check, data originate from an NCEI data source\n",
    "# 5 = Passed all quality control checks, data originate from an NCEI data source\n",
    "# 6 = Suspect, data originate from an NCEI data source\n",
    "# 7 = Erroneous, data originate from an NCEI data source\n",
    "# 9 = Passed gross limits check if element is present\n",
    "# A = Data value flagged as suspect, but accepted as a good value\n",
    "# C = Temperature and dew point received from Automated Weather Observing System (AWOS) are reported in\n",
    "#     whole degrees Celsius. Automated QC flags these values, but they are accepted as valid.\n",
    "# I = Data value not originally in data, but inserted by validator\n",
    "# M = Manual changes made to value based on information provided by NWS or FAA\n",
    "# P = Data value not originally flagged as suspect, but replaced by validator\n",
    "# R = Data value replaced with value computed by NCEI software\n",
    "# U = Data value replaced with edited value \n",
    "#0,1,4,5,9\n",
    "#################################################################################################\n",
    "#VISIBILITY-OBSERVATION variability code [VVVVVV-Type]\n",
    "#The code that denotes whether or not the reported visibility is variable.\n",
    "#DOM: A specific domain comprised of the characters in the ASCII character set.\n",
    "#N = Not variable\n",
    "#V = Variable\n",
    "#9 = Missing\n",
    "#VVVVVV,QC-VVVVVV,Variability,QC-Variability\n",
    "#################################################################################################\n",
    "#WIND-OBSERVATION type code [WND-Type]\n",
    "#The code that denotes the character of the WIND-OBSERVATION.\n",
    "#DOM: A specific domain comprised of the characters in the ASCII character set.\n",
    "#A = Abridged Beaufort\n",
    "#B = Beaufort\n",
    "#C = Calm\n",
    "#H = 5-Minute Average Speed\n",
    "#N = Normal\n",
    "#R = 60-Minute Average Speed\n",
    "#Q = Squall\n",
    "#T = 180 Minute Average Speed\n",
    "#V = Variable\n",
    "#9 = Missing\n",
    "#NOTE: If a value of 9 appears with a wind speed of 0000, this indicates calm winds.\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "#STATION                            = nnnnnnNNNNN                                      = n == USAF identifier (7099999 == none) | N == WBAN identifier\n",
    "#DATE                               = \"YYYY-MM-DDTHH:MM:SS\"\n",
    "#LATITUDE                           = deg. north [+]\n",
    "#LONGITUDE                          = deg. west  [-]\n",
    "#TMP [sfc. temperature]             = TTTT,TTTT-QC                                     = celsius(factor=10),categorical\n",
    "#DEW [sfc. dew point]               = TTTT,TTTT-QC                                     = celsius(factor=10),categorical\n",
    "#WND [sfc. wnd-dir. & wnd-spd.]     = DDD,DDD-QC,WND-Type,WWWW,WWWW-QC                 = degrees,categorical,categorical,meters-per-second,categorical\n",
    "#OC1 [sfc. gust]                    = GGGG,GGGG-GC                                     = meters,categorical\n",
    "#MA1 [altimiter & stat. pres.]      = AAAAA,AAAAA-QC,PPPPP,PPPPP-QC                    = hectopascals(factor=10),categorical,hectopascals(factor=10),categorical \n",
    "#VIS [sfc. visibility]              = VVVVVV,VVVVVV-QC,VVVVVV-Type.,VVVVVV-Type.-QC    = meters,categorical,categorical,categorical\n",
    "#SLP [sea level pressure]           = PPPPP,PPPPP-QC                                   = hectopascals(factor=10),categorical \n",
    "#AA1 [liquid water equivalent]      = DD,PPPP,Trace-QC,PPPP-QC [1-3-6 hourly]          = hours,milimeters(factor=10),categorical\n",
    "#AA2 [liquid water equivalent]      = DD,PPPP,Trace-QC,PPPP-QC [daily]                 = hours,milimeters(factor=10),categorical\n",
    "#\"STATION\",\"DATE\",\"TMP\",\"DEW\",\"WND\",\"OC1\",\"MA1\",\"VIS\",\"SLP\",\"AA1\",\"AA2\"\n",
    "#STATION,DATETIME,DATETIME-VALID,TDIFF,T2,Td,Tw,RH,Q,WS,WD,WG,SLP,SP,LWE\n",
    "#################################################################################################\n",
    "#DERIVED\n",
    "#RH               = e/es * 100% (relative humidity)\n",
    "##### e(celsius)  = 6.11*10**((7.5*Td)/(237.3+Td)) (vapor pressure)\n",
    "##### es(celsius) = 6.11*10**((7.5*T)/(237.3+T)) (saturated vapor pressure)\n",
    "#https://www.weather.gov/media/epz/wxcalc/vaporPressure.pdf [RH]\n",
    "#TW(Celsius,%)    = T * atan(0.151977*(RH+8.313659)**0.5) + atan(T+RH) - atan(RH-1.676331) + 0.00391838*atan(RH)**1.5 * atan(0.023101*RH) - 4.686035 (wet-bulb temperature [Stull 2011])\n",
    "#q                = rv/(1+rv) (specific humidity)\n",
    "##### rv          = (0.622*e)/(P+e) (mixing ratio)\n",
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your Analysis stations\n",
    "from metar import Metar\n",
    "import matplotlib        as mpl\n",
    "from itertools import compress\n",
    "from datetime import timedelta\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytaf\n",
    "import numpy.matlib\n",
    "import dateutil.parser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import atan\n",
    "from os import listdir\n",
    "import sys\n",
    "import requests\n",
    "# https://www.weather.gov/media/asos/aum-toc.pdf\n",
    "# \"In addition, the sensorâ€™s starting threshold for response to wind direction and wind speed is 2 knots. \n",
    "# Winds measured at 2-knots or less are reported as calm.\"\n",
    "WS_TH = 2*0.514444\n",
    "# The minimum gust speed reported by ASOS is 14 knots.\n",
    "WG_TH = 14*0.514444\n",
    "##########################################################################################\n",
    "# Are stations in or out of boundary\n",
    "##########################################################################################\n",
    "def Shrink_Data_to_Domain(XYZ):\n",
    "    Polygon_Log = np.zeros((len(XYZ),1))\n",
    "    for i in range(len(XYZ)):\n",
    "        pt = (float(XYZ[i,2]),float(XYZ[i,1]))\n",
    "        if Point(pt).within(shape(boundary)): # make a point and see if it's in the polygon\n",
    "            Polygon_Log[i,0] = 1\n",
    "    XYZ = np.asarray(list(compress(XYZ,Polygon_Log==1)))\n",
    "    return(XYZ)\n",
    "\n",
    "##########################################################################################\n",
    "# Determine string of date as YYYYMMDDHH\n",
    "##########################################################################################\n",
    "def YYYYMMDDHH_string(Datetime_Value):\n",
    "    if Datetime_Value.month>9:\n",
    "        Month_str = str(Datetime_Value.month)\n",
    "    else:\n",
    "        Month_str = \"0\"+str(Datetime_Value.month)   \n",
    "    if Datetime_Value.day>9:\n",
    "        Day_str = str(Datetime_Value.day)\n",
    "    else:\n",
    "        Day_str = \"0\"+str(Datetime_Value.day)\n",
    "    if Datetime_Value.hour>9:\n",
    "        Hour_str = str(Datetime_Value.hour)\n",
    "    else:\n",
    "        Hour_str = \"0\"+str(Datetime_Value.hour)\n",
    "    return (str(Datetime_Value.year)+Month_str+Day_str+Hour_str)\n",
    "\n",
    "##########################################################################################\n",
    "# Round the observation's time to determine hourly observations\n",
    "##########################################################################################\n",
    "def hour_rounder(t):\n",
    "    # Rounds to nearest hour by adding a timedelta hour if minute >= 30\n",
    "    return (t.replace(second=0, microsecond=0, minute=0, hour=t.hour)\n",
    "               +timedelta(hours=t.minute//30))\n",
    "\n",
    "##########################################################################################\n",
    "# Data conversions\n",
    "##########################################################################################\n",
    "def Temperature_Delim_Calc_C(Temperature_Cell): #TEMPERATURE\n",
    "    T2_C = np.nan\n",
    "    if len(Temperature_Cell[\"TMP\"])>0: # SFC TEMPERATURE\n",
    "        Temp_Obs = Temperature_Cell[\"TMP\"].split(',')\n",
    "        if Temp_Obs[1] == '0' or Temp_Obs[1] == '1' or Temp_Obs[1] == '4' or Temp_Obs[1] == '5' \\\n",
    "        or Temp_Obs[1] == '9' or Temp_Obs[1].isalpha():\n",
    "            T2_C = float(Temp_Obs[0])/10 #celsius\n",
    "            if T2_C > 100:\n",
    "                T2_C = np.nan\n",
    "    return (T2_C)\n",
    "\n",
    "def DewPoint_Delim_Calc_C(DewPoint_Cell): #DEW POINT TEMPERATURE\n",
    "    DP2_C = np.nan\n",
    "    if len(DewPoint_Cell[\"DEW\"])>0:\n",
    "        DP_Obs = DewPoint_Cell[\"DEW\"].split(',')\n",
    "        if DP_Obs[1] == '0' or DP_Obs[1] == '1' or DP_Obs[1] == '4' or DP_Obs[1] == '5' \\\n",
    "        or DP_Obs[1] == '9' or DP_Obs[1].isalpha():\n",
    "            DP2_C = float(DP_Obs[0])/10\n",
    "            if DP2_C > 100:\n",
    "                DP2_C = np.nan\n",
    "    return (DP2_C)\n",
    "\n",
    "def WindGust_Delim_Calc_ms(WindGust_Cell): #WIND GUST\n",
    "    WG_ms = np.nan\n",
    "    if len(WindGust_Cell[\"OC1\"])>0: \n",
    "        WG_Obs = WindGust_Cell[\"OC1\"].split(',')\n",
    "        if WG_Obs[1] == '0' or WG_Obs[1] == '1' or WG_Obs[1] == '4' or WG_Obs[1] == '5' \\\n",
    "        or WG_Obs[1] == '9' or WG_Obs[1].isalpha():\n",
    "            WG_ms = float(WG_Obs[0])/10 #celsius\n",
    "            if WG_ms > 100:\n",
    "                WG_ms = np.nan\n",
    "            elif WG_ms<WG_TH:\n",
    "                WG_ms = np.nan\n",
    "    return (WG_ms)\n",
    "\n",
    "def WindSp_WindDir_Calc_ms_deg(Wind_Cell): #WIND SPEED | WIND DIRECTION\n",
    "    wsms_wddeg = np.nan,np.nan\n",
    "    if len(Wind_Cell[\"WND\"])>0:\n",
    "        Wind_Obs = Wind_Cell[\"WND\"].split(',')\n",
    "        if Wind_Obs[1] == '0' or Wind_Obs[1] == '1' or Wind_Obs[1] == '4' or Wind_Obs[1] == '5' \\\n",
    "        or Wind_Obs[1] == '9' or Wind_Obs[1].isalpha():\n",
    "            if Wind_Obs[2] == \"N\":\n",
    "                wsms_wddeg = float(Wind_Obs[3])/10,float(Wind_Obs[0]) #degrees \n",
    "            elif Wind_Obs[2] == \"C\" or Wind_Obs[2] == '9':\n",
    "                wsms_wddeg = np.nan,np.nan\n",
    "        if wsms_wddeg[0]<WS_TH:\n",
    "            wsms_wddeg = np.nan,np.nan\n",
    "        elif wsms_wddeg[0]>100:\n",
    "            wsms_wddeg = np.nan,np.nan\n",
    "        elif wsms_wddeg[1]>361:\n",
    "            wsms_wddeg = np.nan,np.nan\n",
    "    return (wsms_wddeg) \n",
    "\n",
    "def StationPres_Alt_Calc_hpa(Pressure_Cell): #STATION PRESSURE\n",
    "    SP_hpa = np.nan\n",
    "    if len(Pressure_Cell[\"MA1\"])>0:\n",
    "        Pressure = Pressure_Cell[\"MA1\"].split(',')\n",
    "        if Pressure[3] == '0' or Pressure[3] == '1' or Pressure[3] == '4' or Pressure[3] == '5' \\\n",
    "        or Pressure[3] == '9' or Pressure[3].isalpha():\n",
    "            SP_hpa = (float(Pressure[2])/10)*100 \n",
    "            if SP_hpa > 200000:\n",
    "                SP_hpa = np.nan\n",
    "    return (SP_hpa)    \n",
    "\n",
    "def Precipitation_Type(METAR_Remark_Cell):\n",
    "    Parsed_METAR = METAR_Remark_Cell['REM']\n",
    "    if \"METAR\" in Parsed_METAR:\n",
    "        Parsed_METAR = Parsed_METAR[Parsed_METAR.index('METAR'):]\n",
    "        #print(Parsed_METAR)\n",
    "        try:\n",
    "            TAF_report = pytaf.TAF(Parsed_METAR)\n",
    "            taskbarskies = True\n",
    "        except:\n",
    "            taskbarskies = False\n",
    "            pass # doing nothing on exception              \n",
    "        if taskbarskies == True:\n",
    "            TAF_report = pytaf.TAF(Parsed_METAR)\n",
    "            decoder    = pytaf.Decoder(TAF_report)\n",
    "            TAF_report = decoder.decode_taf()\n",
    "            TAF_report = str(np.asarray(TAF_report))\n",
    "            TAF_report = TAF_report.split('\\n')\n",
    "            Type = []\n",
    "            for i in range(len(TAF_report)):\n",
    "                if \"Weather:\" in TAF_report[i]:\n",
    "                    Type = str(TAF_report[i])\n",
    "                    break\n",
    "            if len(Type)>0:\n",
    "                Type_str = str(Type.replace(\"Weather:\",\"\")).strip()\n",
    "                if \"/\" in Type:\n",
    "                    Type_str = Type_str.split('/')\n",
    "                    Type_str = Type_str[0].strip()\n",
    "                else:\n",
    "                    Type_str = Type_str.strip()\n",
    "            else:\n",
    "                Type_str = 'Fair_wx'\n",
    "        else:\n",
    "            Type_str = 'Failed_Parsed'\n",
    "    else:\n",
    "        Type_str = 'Not_Parsed'\n",
    "    return(Type_str)\n",
    "\n",
    "def Visibility_meters(Visibility_Cell):\n",
    "    VIS_m = np.nan\n",
    "    if len(Visibility_Cell[\"VIS\"])>0:\n",
    "        Visibility = Visibility_Cell[\"VIS\"].split(',')\n",
    "        if Visibility[1] == '0' or Visibility[1] == '1' or Visibility[1] == '4' or Visibility[1] == '5' \\\n",
    "        or Visibility[1] == '9' or Visibility[1].isalpha():\n",
    "            VIS_m = float(Visibility[0])\n",
    "            if VIS_m == 999999:\n",
    "                VIS_m = np.nan\n",
    "    return (VIS_m)    \n",
    "\n",
    "##########################################################################################\n",
    "# CALCULATIONS\n",
    "##########################################################################################\n",
    "\n",
    "def Specific_Humidity(Dew_Temperature_C,Station_Pressure_pat):\n",
    "    e = 6.11*10**((7.5*Dew_Temperature_C)/(237.3+Dew_Temperature_C))\n",
    "    rv = (0.622*e)/(Station_Pressure_pat+e)\n",
    "    sh = rv/(1+rv)*100\n",
    "    return (sh)\n",
    "\n",
    "def Relative_Humidity(Temperature_C,Dew_Temperature_C):\n",
    "    e  = 6.11*10**((7.5*Dew_Temperature_C)/(237.3+Dew_Temperature_C))\n",
    "    es = 6.11*10**((7.5*Temperature_C)/(237.3+Temperature_C))\n",
    "    RH = (e/es) * 100\n",
    "    return (RH)\n",
    "\n",
    "def Wet_Bulb_Stull(Temperature_C,RH_perc):\n",
    "    C1 = 0.151977 #Stull Tw\n",
    "    C2 = 8.313659 #Stull Tw \n",
    "    C3 = 1.676331 #Stull Tw\n",
    "    C4 = 0.00391838 #Stull Tw\n",
    "    C5 = 0.023101 #Stull Tw\n",
    "    C6 = 4.686035 #Stull Tw\n",
    "    tw = Temperature_C*atan(C1*(RH_perc+C2)**0.5)+atan(Temperature_C+RH_perc)-atan(RH_perc-C3)+C4*((RH_perc)**1.5)*atan(C5*RH_perc)-C6\n",
    "    return (tw)\n",
    "\n",
    "##########################################################################################\n",
    "# COMPILING CSV FILES INTO AN EVENT FILE\n",
    "##########################################################################################\n",
    "def find_csv_filenames( path_to_dir, suffix=\".csv\" ):\n",
    "    filenames = listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith( suffix ) ]\n",
    "\n",
    "##########################################################################################\n",
    "# WILL IT FINISH SOON???\n",
    "##########################################################################################\n",
    "def progressBar(value, endvalue, bar_length=20):\n",
    "\n",
    "    percent = float(value) / endvalue\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "\n",
    "    sys.stdout.write(\"\\rPercent: [{0}] {1}%\".format(arrow + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-02-24 06:00:00\n",
      "Percent: [------------------->] 99%2011-02-01 00:00:00\n",
      "Percent: [------------------->] 99%2011-01-26 00:00:00\n",
      "Percent: [------------------->] 99%2011-01-11 12:00:00\n",
      "Percent: [------------------->] 99%2010-12-25 06:00:00\n",
      "Percent: [------------------->] 99%2010-02-15 18:00:00\n",
      "Percent: [------------------->] 99%2010-02-09 12:00:00\n",
      "Percent: [------------------->] 99%2009-12-29 00:00:00\n",
      "Percent: [------------------->] 99%2009-12-19 00:00:00\n",
      "Percent: [------------------->] 99%2009-12-08 12:00:00\n",
      "Percent: [------------------->] 99%2009-03-01 00:00:00\n",
      "Percent: [------------------->] 99%2009-02-22 00:00:00\n",
      "Percent: [------------------->] 99%2008-12-20 12:00:00\n",
      "Percent: [------------------->] 99%2008-12-19 00:00:00\n",
      "Percent: [------------------->] 99%2007-12-02 06:00:00\n",
      "Percent: [------------------->] 99%2007-04-03 18:00:00\n",
      "Percent: [------------------->] 99%2007-03-15 00:00:00\n",
      "Percent: [------------------->] 99%2006-02-11 06:00:00\n",
      "Percent: [------------------->] 99%"
     ]
    }
   ],
   "source": [
    "#https://www.ncei.noaa.gov/data/global-hourly/access/\n",
    "#https://www.ncei.noaa.gov/data/global-hourly/doc/CSV_HELP.pdf\n",
    "#https://www.ncei.noaa.gov/data/global-hourly/doc/isd-format-document.pdf\n",
    "#https://www.ncdc.noaa.gov/isd\n",
    "######################################################################################\n",
    "###SIMULATION CONSTANTS\n",
    "######################################################################################\n",
    "Time_diff_limit_mins     = 30 #Ant obs-valid time > Time_diff_limit_mins will be excluded\n",
    "QCLCD_dir                = r'https://www.ncei.noaa.gov/data/global-hourly/access/'\n",
    "Events_List              = pd.read_csv(r'C:/Users/Mike/Desktop/QCLCD/Events.csv')\n",
    "QCLCD_station_csv        = pd.read_csv(r'C:/Users/Mike/Desktop/QCLCD/WWE_Stations_WBANxy.csv')\n",
    "#QCLCD_station_csv.rename(columns={0:'File_Name',1:'Lat',2:'Lon'}, inplace=True)\n",
    "Spinup                   = int(12) # ADD A SPINUP TIME... SET TO 0 IF NO SPINUP TIME\n",
    "\n",
    "for x in range(len(Events_List)): # Event loop\n",
    "    ######################################################################################\n",
    "    ###START TIME AND END TIME FOR OBSERVATION WEBSCRAPE\n",
    "    ######################################################################################\n",
    "    Initialization_Year      = Events_List['Start_Year'][x]\n",
    "    Initialization_Month     = Events_List['Start_Month'][x]\n",
    "    Initialization_Day       = Events_List['Start_Day'][x]\n",
    "    Initialization_Hour      = Events_List['Start_Hour'][x]\n",
    "    Initialization_Durration = Events_List['Durration'][x]\n",
    "    ### Obtain the Start and End Times of the Simulation\n",
    "    Datetime_Initialization  = datetime(Initialization_Year, Initialization_Month, Initialization_Day,Initialization_Hour,0,0)+timedelta(hours=Spinup)\n",
    "    print(Datetime_Initialization)\n",
    "    Datetime_Termination     = Datetime_Initialization+timedelta(hours=int(Initialization_Durration))\n",
    "    ### End times\n",
    "    if Datetime_Termination.month>9:\n",
    "         Month_str = str(Datetime_Termination.month)\n",
    "    else:\n",
    "        Month_str = \"0\"+str(Datetime_Termination.month)   \n",
    "    if Datetime_Termination.day>9:\n",
    "        Day_str = str(Datetime_Termination.day)\n",
    "    else:\n",
    "        Day_str = \"0\"+str(Datetime_Termination.day)\n",
    "    str_end = str(Datetime_Termination.year)+Month_str+Day_str\n",
    "    ### Start times\n",
    "    if Datetime_Initialization.month>9:\n",
    "        Month_str = str(Datetime_Initialization.month)\n",
    "    else:\n",
    "        Month_str = \"0\"+str(Datetime_Initialization.month)   \n",
    "    if Datetime_Initialization.day>9:\n",
    "        Day_str = str(Datetime_Initialization.day)\n",
    "    else:\n",
    "        Day_str = \"0\"+str(Datetime_Initialization.day)\n",
    "    str_begin = str(Datetime_Initialization.year)+Month_str+Day_str\n",
    "    ######################################################################################\n",
    "    ###STATION WEBSCRAPING BASED ON DATE\n",
    "    ######################################################################################    \n",
    "    for y in range(len(QCLCD_station_csv)): #Station loop\n",
    "        url = QCLCD_dir+str(Initialization_Year)+\"/\"+str(QCLCD_station_csv[\"File_Name\"][y])+\".csv\"\n",
    "        Check_station_metadata = requests.head(url)\n",
    "        Check_station_metadata = Check_station_metadata.headers\n",
    "        Check_station_metadata = pd.DataFrame.from_dict(Check_station_metadata)\n",
    "        Check_log = np.sum(Check_station_metadata == \"ETag\")\n",
    "        if Check_log[0]>0: #Is data for 'y' station available on said date?\n",
    "            Data_Server   = str_begin+\"_\"+str_end+\"_\"+str(QCLCD_station_csv[\"File_Name\"][y])\n",
    "            QCLCD_Station = str(QCLCD_station_csv[\"File_Name\"][y])\n",
    "            #print(\"Downloading Data for Station: \"+QCLCD_Station)\n",
    "            #########################################################################################################\n",
    "            ### ***SHRINK DATA*** ###\n",
    "            #########################################################################################################\n",
    "            # variables for analysis (shrink dataframe)\n",
    "            Compressed_QCLCD = pd.read_csv(QCLCD_dir+\"/\"+str(Datetime_Initialization.year)+\"/\"+QCLCD_Station+\".csv\",dtype=object)\n",
    "            # time-window for analysis (shrink dataframe)\n",
    "            start_time       = Datetime_Initialization\n",
    "            start_end        = Datetime_Termination\n",
    "            # datetime of observation\n",
    "            datetime_station = np.expand_dims(Compressed_QCLCD[\"DATE\"].to_numpy(dtype=str),1)\n",
    "            # determine if the observation falls within the time-window for analysis\n",
    "            row_logical      = np.zeros((len(datetime_station), 1))\n",
    "            for i in range(len(row_logical)): #Is the date within the time of analysis?\n",
    "                if start_time <= dateutil.parser.parse(datetime_station[i,0]) <= start_end:\n",
    "                    row_logical[i,0] = True   \n",
    "            # add boolean results back into the original dataframe [did the observation fall w/in the analysis time-window]\n",
    "            Compressed_QCLCD['Date_Boolean'] = pd.DataFrame(row_logical)\n",
    "            # remove 'false' boolean results\n",
    "            Compressed_QCLCD                 = Compressed_QCLCD[Compressed_QCLCD.Date_Boolean != 0]\n",
    "            # replace 'nan' values with empty strings for data-processing\n",
    "            Compressed_QCLCD                 = Compressed_QCLCD.replace(np.nan, '', regex=True).reset_index()\n",
    "            # create an array filled with the station's wmo/wban identifiers\n",
    "            Stations                         = np.matlib.repmat(QCLCD_Station, len(Compressed_QCLCD), 1)\n",
    "            #########################################################################################################\n",
    "            ### ***DETERMINE TIMES & T-DIFF*** ###\n",
    "            #########################################################################################################\n",
    "            # preallocate arrays to determine hourly observations (comparing vs. NWP hourly output)\n",
    "            d = len(Compressed_QCLCD)\n",
    "            Time_Matrix = np.empty([d,3], dtype=object)\n",
    "            time_valid  = np.empty([d,1], dtype=object)\n",
    "            Date_times  = np.empty([d,1], dtype=object)\n",
    "            # determine the time difference (minutes) b/n the nearest hour vs. the observation's time,\n",
    "            # return a matrix of the observation's rounded YYYY, MM, DD, HH, and TDIFF \n",
    "            for i in range(d):\n",
    "                Date_times[i,0]     = dateutil.parser.parse(Compressed_QCLCD[\"DATE\"][i])\n",
    "                time_round          = hour_rounder(Date_times[i,0])\n",
    "                time_valid[i,0]     = datetime.strptime(str(Date_times[i,0]), '%Y-%m-%d %H:%M:%S')\n",
    "                tdiff               = abs(time_valid[i,0]-time_round)\n",
    "                tdiff               = int(tdiff.seconds/60)\n",
    "                Time_Matrix[i,:]    = Compressed_QCLCD[\"DATE\"][i],YYYYMMDDHH_string(time_round),str(tdiff)\n",
    "            Dates       = np.unique(Time_Matrix[:,1])\n",
    "            row_logical = np.zeros((len(Time_Matrix[:,1]), 1))\n",
    "            for z in range(len(Dates)):\n",
    "                Log_Key = np.expand_dims(Time_Matrix[:,1]==Dates[z],1)\n",
    "                if len(Log_Key>0):\n",
    "                    row             = [i for i, j in enumerate(Log_Key) if j]\n",
    "                    Key_Time_Matrix = Time_Matrix[row]\n",
    "                    row_check       = np.argmin(np.array(Key_Time_Matrix[:,2], dtype=np.float), axis=None, out=None)\n",
    "                    row             = row[row_check]\n",
    "                    row_logical[row,0] = 1\n",
    "            Compressed_QCLCD = pd.concat([Compressed_QCLCD, pd.DataFrame(Time_Matrix)], axis=1)\n",
    "            if len(Compressed_QCLCD)>0:\n",
    "                Compressed_QCLCD['Hourly_Boolean'] = pd.DataFrame(row_logical)\n",
    "                Compressed_QCLCD = Compressed_QCLCD.rename(columns={0: \"Date_Time_Obs\", 1: \"Date_Valid_Hour\",2:\"Time_Diff_mins\"})\n",
    "                Compressed_QCLCD = Compressed_QCLCD[Compressed_QCLCD.Hourly_Boolean != 0].reset_index()\n",
    "                Compressed_QCLCD = Compressed_QCLCD[pd.to_numeric(Compressed_QCLCD['Time_Diff_mins'])<Time_diff_limit_mins]\n",
    "                #########################################################################################################\n",
    "                ### ***ADD MANDATORY COLUMNS IF NOT AVAILABLE THEN SHRINK DATA*** ###\n",
    "                #########################################################################################################\n",
    "                # variables for analysis (shrink dataframe)\n",
    "                if 'STATION' not in Compressed_QCLCD: Compressed_QCLCD['STATION'] = ''    \n",
    "                if 'DATE' not in Compressed_QCLCD: Compressed_QCLCD['DATE'] = ''    \n",
    "                if 'TMP' not in Compressed_QCLCD: Compressed_QCLCD['TMP'] = ''    \n",
    "                if 'DEW' not in Compressed_QCLCD: Compressed_QCLCD['DEW'] = ''    \n",
    "                if 'WND' not in Compressed_QCLCD: Compressed_QCLCD['WND'] = ''    \n",
    "                if 'OC1' not in Compressed_QCLCD: Compressed_QCLCD['OC1'] = ''    \n",
    "                if 'MA1' not in Compressed_QCLCD: Compressed_QCLCD['MA1'] = ''    \n",
    "                if 'VIS' not in Compressed_QCLCD: Compressed_QCLCD['VIS'] = ''    \n",
    "                if 'SLP' not in Compressed_QCLCD: Compressed_QCLCD['SLP'] = ''    \n",
    "                if 'AA1' not in Compressed_QCLCD: Compressed_QCLCD['AA1'] = ''   \n",
    "                if 'AA2' not in Compressed_QCLCD: Compressed_QCLCD['AA2'] = '' \n",
    "                if 'REM' not in Compressed_QCLCD: Compressed_QCLCD['REM'] = '' \n",
    "                Compressed_QCLCD = Compressed_QCLCD[[\"STATION\",\"DATE\",\"Date_Valid_Hour\",\"Time_Diff_mins\",\"TMP\",\"DEW\",\"WND\",\"OC1\",\"MA1\",\"VIS\",\n",
    "                                                     \"SLP\",\"AA1\",\"AA2\",\"REM\"]]\n",
    "                QCLC_DATA        = np.empty((len(Compressed_QCLCD), 15), dtype=object)\n",
    "                #########################################################################################################\n",
    "                ### ***CALCULATIONS*** ###\n",
    "                #########################################################################################################\n",
    "                for j in range(len(Compressed_QCLCD)):\n",
    "                    # metadata for the observations that match the query time\n",
    "                    QCLCD_tm      = Compressed_QCLCD.iloc[j,:]\n",
    "                    Station       = QCLCD_tm[\"STATION\"]\n",
    "                    Date_Valid    = QCLCD_tm[\"Date_Valid_Hour\"]\n",
    "                    Date_Obs      = QCLCD_tm[\"DATE\"]\n",
    "                    Time_Diff_m   = QCLCD_tm[\"Time_Diff_mins\"]\n",
    "                    T2_C          = Temperature_Delim_Calc_C(QCLCD_tm)                    #2-M TEMPERATURE celsius\n",
    "                    Td_C          = DewPoint_Delim_Calc_C(QCLCD_tm)                       #2-M DEW POINT TEMPERATURE celsius\n",
    "                    WSms_WDdeg    = WindSp_WindDir_Calc_ms_deg(QCLCD_tm)            #WIND DIRECTION degrees | WIND SPEED m/s\n",
    "                    WG_ms         = WindGust_Delim_Calc_ms(QCLCD_tm)                     #WIND GUST m/s\n",
    "                    SP_hpa        = StationPres_Alt_Calc_hpa(QCLCD_tm)                  #STATION PRESSURE hpa\n",
    "                    Vis_m         = Visibility_meters(QCLCD_tm)\n",
    "                    # calculate variables that are not readilly available by QCLCD\n",
    "                    RH         = np.round(Relative_Humidity(T2_C,Td_C),2)                #RELATIVE HUMIDITY percent\n",
    "                    Tw_C       = np.round(Wet_Bulb_Stull(T2_C,RH),2)                   #WET BULB TEMPERATURE celsius\n",
    "                    SH         = Specific_Humidity(Td_C,SP_hpa)                          #SPECIFIC HUMIDITY kg/kg     \n",
    "                    # precipitation type and sky condition\n",
    "                    PType      = Precipitation_Type(QCLCD_tm)\n",
    "                    #print(QCLCD_tm['REM'])\n",
    "                    #print(PType)\n",
    "                    #sleep(5)\n",
    "                    # compiled observations\n",
    "                    QCLC_DATA[j,:] = np.transpose(np.expand_dims(numpy.asarray([Station,Date_Valid,Date_Obs,\n",
    "                                                                                Time_Diff_m,T2_C,Td_C,Tw_C,RH,SH,\n",
    "                                                                                WSms_WDdeg[1],WSms_WDdeg[0],WG_ms,SP_hpa,\n",
    "                                                                                Vis_m,PType],dtype=object),1))            \n",
    "\n",
    "                QCLC_DATA = QCLC_DATA[QCLC_DATA[:, 1].argsort()]\n",
    "                np.savetxt(Data_Server+\".txt\", QCLC_DATA, delimiter=\",\",\n",
    "                               fmt='%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s')\n",
    "                progressBar(y, len(QCLCD_station_csv), bar_length=20)\n",
    "    #########################################################################################################\n",
    "    ### CREATING ONE FILE FOR ONE EVENT, MOVING ALL FILES INTO A DIRECTORY###\n",
    "    #########################################################################################################\n",
    "    outfilename = str_begin+\"_\"+str_end+\".csv\"\n",
    "    with open(outfilename, 'wb') as outfile:\n",
    "        for filename in glob.glob('*.txt'):\n",
    "            if filename == outfilename:\n",
    "                    # don't want to copy the output into the output\n",
    "                continue\n",
    "            with open(filename, 'rb') as readfile:\n",
    "                shutil.copyfileobj(readfile, outfile)\n",
    "    os.mkdir('C:/Users/Mike/'+str_begin+\"_\"+str_end+\"_ISD\") \n",
    "    Text_Files_ISD = find_csv_filenames('C:/Users/Mike/', suffix=\".txt\")     \n",
    "    for i in range(len(Text_Files_ISD)):\n",
    "        shutil.move(Text_Files_ISD[i], 'C:/Users/Mike/'+str_begin+\"_\"+str_end+\"_ISD\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
